{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling ESC-50 dataset\n",
    "\n",
    "Notebook for testing dataset interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torchaudio.functional as F\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base class for all datasets\n",
    "\n",
    "class BaseAudioDataset(Dataset, ABC):\n",
    "    \"\"\"Abstract base class for audio datasets\"\"\"\n",
    "    def __init__(self, root_dir, sr=None, duration=None, normalize=None, feature_extractor=None, time_augs=None, feature_augs=None):\n",
    "        \"\"\"\n",
    "        root_dir: path to dataset directory\n",
    "        sr: sampling rate (default - None == each file keeps it's original sr)\n",
    "        duration: duration of audios in seconds (default - None == keep original duration)\n",
    "        normalize: type of audio normalization (currently only peak norm is supported) (default - None)\n",
    "        feature_extractor: a transform object which performs feature extraction \n",
    "            (default - None for e2e systems or when feature extraction is performed elsewhere)\n",
    "        time_augs: a transofrm or a sequence of transforms applied to wavs during training (default - None)\n",
    "        feature_augs: a transofrm or a sequence of transforms applied to features during training (default - None)\n",
    "        \"\"\"\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.sr = sr\n",
    "        self.duration = duration\n",
    "        if sr is not None and duration is not None:\n",
    "            self.num_frames = int(sr * duration)\n",
    "        else:\n",
    "            self.num_frames = -1\n",
    "        self.normalize = normalize\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.time_augs = time_augs\n",
    "        self.feature_augs = feature_augs\n",
    "        self.metadata = self.load_metadata()\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_metadata(self):\n",
    "        \"\"\"Loads data from corresponding metafile and converts it to format path_to_audio, target\"\"\"\n",
    "        pass\n",
    "\n",
    "    def _fix_length(self, audio, num_frames_orig):\n",
    "        if audio.shape[1] < num_frames_orig:\n",
    "            pad_frames = num_frames_orig - audio.shape[1]\n",
    "            return torch.nn.functional.pad(audio, (0, pad_frames))\n",
    "        elif audio.shape[1] > num_frames_orig:\n",
    "            return audio[..., :num_frames_orig]\n",
    "        return audio\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.metadata.loc[idx, \"path_to_audio\"]\n",
    "        target = torch.tensor(self.metadata.loc[idx, \"target\"], dtype=torch.long)\n",
    "\n",
    "        audio, original_sr = torchaudio.load(audio_path, num_frames=self.num_frames)\n",
    "\n",
    "        # convert to mono if necessary\n",
    "        if audio.shape[0] > 1:\n",
    "            audio = torch.mean(audio, dim=0, keepdim=True)\n",
    "\n",
    "        # resample if necessary\n",
    "        if original_sr != self.sr:\n",
    "            audio = F.resample(audio, original_sr, self.sr)\n",
    "\n",
    "        # normalization\n",
    "        if self.normalize is not None:\n",
    "            abs_max = audio.abs().max()\n",
    "            if abs_max != 0.:\n",
    "                audio /= abs_max\n",
    "\n",
    "        _, num_frames_orig = audio.shape\n",
    "\n",
    "        if self.time_augs is not None:\n",
    "            audio = self.time_augs(audio)\n",
    "\n",
    "        audio = self._fix_length(audio, num_frames_orig)\n",
    "\n",
    "        if self.feature_extractor is not None:\n",
    "            features = self.feature_extractor(audio)\n",
    "        else:\n",
    "            features = audio\n",
    "\n",
    "        if self.feature_augs is not None:\n",
    "            features = self.feature_augs(features)\n",
    "\n",
    "        return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESC50dataset(BaseAudioDataset):\n",
    "    \"\"\"Class to work with ESC-50 dataset\"\"\"\n",
    "    def __init__(self, root_dir, folds=None, sr=44100, duration=5.0, normalize=None, feature_extractor=None, time_augs=None, feature_augs=None):\n",
    "        \"\"\"\n",
    "        root_dir: path to dataset directory\n",
    "        folds (int, list, tuple): folds that will be used in the current subset\n",
    "        sr: sampling rate (default - None == each file keeps it's original sr)\n",
    "        duration: duration of audios in seconds (default - None == keep original duration)\n",
    "        feature_extractor: a transform object which performs feature extraction \n",
    "            (default - None for e2e systems or when feature extraction is performed elsewhere)\n",
    "        augmentations: a transofrm or a sequence of transforms used during training (default - None)\n",
    "        \"\"\"\n",
    "        self.folds = self.validate_folds(folds)\n",
    "\n",
    "        super().__init__(root_dir, sr, duration, normalize, feature_extractor, time_augs, feature_augs)\n",
    "\n",
    "    def validate_folds(self, folds):\n",
    "        if folds is None:\n",
    "            return [1, 2, 3, 4, 5]\n",
    "        elif isinstance(folds, int):\n",
    "             return [folds]\n",
    "        elif isinstance(folds, tuple) or isinstance(folds, list):\n",
    "                if set(folds).issubset({1, 2, 3, 4, 5}):\n",
    "                     return list(folds)\n",
    "                else:\n",
    "                     raise ValueError(f\"Invalid folds {folds}. ESC-50 has folds 1, 2, 3, 4, 5\")\n",
    "        else:\n",
    "            raise TypeError(f\"folds must be int, list or tuple\")\n",
    "\n",
    "    def load_metadata(self):\n",
    "        meta_path = os.path.join(self.root_dir, \"meta\", \"esc50.csv\")\n",
    "        meta = pd.read_csv(meta_path)\n",
    "\n",
    "        # leave necessary folds\n",
    "        meta = meta[meta[\"fold\"].isin(self.folds)]\n",
    "        meta = meta[[\"filename\", \"target\"]]\n",
    "\n",
    "        # turn filenames into paths\n",
    "        meta.loc[:, \"filename\"] = meta[\"filename\"].apply(lambda fn: os.path.join(self.root_dir, \"audio\", fn))\n",
    "\n",
    "        # rename columns\n",
    "        metadata = meta.rename(columns={\"filename\": \"path_to_audio\"})\n",
    "\n",
    "        return metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
