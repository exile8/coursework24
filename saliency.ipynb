{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuliya/coursework24/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from audiointerp.dataset.esc50 import ESC50dataset\n",
    "from audiointerp.model.cnn14 import TransferCnn14\n",
    "from audiointerp.interpretation.saliency import SaliencyInterpreter\n",
    "from audiointerp.metrics import Metrics\n",
    "from audiointerp.processing.spectrogram import LogMelSTFTSpectrogram\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio.transforms as T\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/yuliya/ESC50\"\n",
    "sr = 32000\n",
    "test_folds = [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 1024\n",
    "hop_length = 320\n",
    "win_length = 1024\n",
    "n_mels = 64\n",
    "f_min = 50\n",
    "f_max = 14000\n",
    "top_db = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = LogMelSTFTSpectrogram(n_fft=n_fft, win_length=win_length, hop_length=hop_length, power=2.0,\n",
    "                                          n_mels=n_mels, sample_rate=sr, f_min=f_min, f_max=f_max, top_db=80,\n",
    "                                          return_phase=False, return_full_db=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ESC50dataset(root_dir=root_dir, sr=sr, folds=test_folds, feature_extractor=feature_extractor)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransferCnn14(50)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"best.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_step(model, criterion, dataloader, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for samples, labels in dataloader:\n",
    "            samples = samples.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(samples)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * samples.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total_samples += samples.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_corrects.double() / total_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.59, Test acc: 0.85\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = valid_step(model, criterion, test_loader, device)\n",
    "print(f\"Test loss: {test_loss:.2f}, Test acc: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = 0\n",
    "dd = 0\n",
    "cc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_and_evaluate(model, test_loader, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    saliency = SaliencyInterpreter(model)\n",
    "    results = {\n",
    "        \"FF\": [],\n",
    "        \"AI\": [],\n",
    "        \"AD\": [],\n",
    "        \"AG\": [],\n",
    "        \"FidIn\": [],\n",
    "        \"SPS\": [],\n",
    "        \"COMP\": []\n",
    "    }\n",
    "    \n",
    "    for inputs, _ in test_loader:\n",
    "        inputs = inputs.to(device).requires_grad_(True)\n",
    "        \n",
    "        logits = model(inputs)\n",
    "        predicted_class = logits.argmax(dim=1)\n",
    "\n",
    "        intr, mask = saliency.interpret(inputs).values()\n",
    "\n",
    "        unmasked_inputs = (inputs - inputs.amin(dim=(1, 2, 3), keepdim=True)) * (1 - mask) + inputs.amin(dim=(1, 2, 3), keepdim=True)\n",
    "        masked_inputs = (inputs - inputs.amin(dim=(1, 2, 3), keepdim=True)) * mask + inputs.amin(dim=(1, 2, 3), keepdim=True)\n",
    "\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            logits_original = model(inputs)\n",
    "            logits_masked = model(masked_inputs)\n",
    "            logits_unmasked = model(unmasked_inputs)\n",
    "        \n",
    "        \n",
    "        ff = Metrics.compute_FF(logits=logits_original, logits_out=logits_unmasked)\n",
    "        ai = Metrics.compute_AI(logits=logits_original, logits_in=logits_masked)\n",
    "        ad = Metrics.compute_AD(logits=logits_original, logits_in=logits_masked)\n",
    "        ag = Metrics.compute_AG(logits=logits_original, logits_in=logits_masked)\n",
    "        fidin = Metrics.compute_FidIn(logits=logits_original, logits_in=logits_masked)\n",
    "        sps = Metrics.compute_SPS(inputs, mask, logits, device)\n",
    "        comp = Metrics.compute_COMP(inputs, mask, logits, device)\n",
    "\n",
    "        results[\"FF\"].append(ff.cpu())\n",
    "        results[\"AI\"].append(ai.cpu())\n",
    "        results[\"AD\"].append(ad.cpu())\n",
    "        results[\"AG\"].append(ag.cpu())\n",
    "        results[\"FidIn\"].append(fidin.cpu())\n",
    "        results[\"SPS\"].append(torch.tensor(sps).cpu())\n",
    "        results[\"COMP\"].append(torch.tensor(comp).cpu())\n",
    "    \n",
    "    for m in results:\n",
    "        results[m] = torch.cat(results[m])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = interpret_and_evaluate(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FF': tensor([ 4.3904e+00,  2.6829e+00,  3.6084e+00,  5.6793e+00,  5.9127e+00,\n",
       "          3.9587e+00,  9.3576e-01,  1.7623e+00,  3.3140e+00,  2.1677e+00,\n",
       "          5.7285e-01,  6.0738e+00,  1.8183e+00,  1.2579e+00,  2.4334e+00,\n",
       "          1.9704e+00,  5.6164e+00,  4.5580e+00,  4.5498e+00,  1.6505e+00,\n",
       "          5.5468e-01,  5.1951e+00,  6.0582e+00,  4.0452e+00,  2.2318e+00,\n",
       "          5.4364e+00,  2.7789e+00, -6.1002e-03,  5.3026e+00,  4.0927e+00,\n",
       "          1.5172e+00,  1.6669e+00,  1.3521e+00,  1.5379e+00, -5.0180e-01,\n",
       "          3.2094e-02,  3.4421e+00,  1.3970e+00,  2.6572e+00, -4.2262e-01,\n",
       "         -6.3466e-01,  6.0423e-01,  5.0393e+00,  5.1226e+00,  5.3212e+00,\n",
       "          7.1753e+00,  6.1805e-02, -8.9615e-01,  1.6967e-01,  6.7778e+00,\n",
       "          2.4765e-01,  8.2382e-02,  3.5105e+00, -2.8991e+00,  1.6720e+00,\n",
       "          2.9569e+00,  5.4435e+00,  2.3113e+00,  1.0384e+01,  7.1298e-01,\n",
       "          1.6891e+00,  6.3732e+00,  3.6298e+00,  1.7211e+00,  3.9837e+00,\n",
       "          1.6318e+00,  5.6164e+00,  6.4096e+00,  6.2972e+00,  1.3688e+00,\n",
       "          1.8001e+00,  1.1046e+00,  3.4086e+00,  2.3996e+00,  2.3254e+00,\n",
       "          3.2059e+00,  8.9198e+00,  1.0085e+00,  4.2852e+00,  8.8079e-01,\n",
       "          8.0972e+00,  6.1164e+00,  7.5495e+00, -1.5419e-01,  2.3266e-01,\n",
       "          4.0366e-01,  2.9609e+00,  3.1026e+00,  1.4928e+00,  5.0524e+00,\n",
       "          1.2484e+00,  1.5233e+00,  5.2314e+00,  1.8307e+00,  3.4328e+00,\n",
       "          1.9624e-02,  2.0690e+00,  5.7257e+00,  4.7502e+00,  2.6655e+00,\n",
       "          5.2815e+00,  6.2564e-01,  7.4541e-01, -6.7316e-01,  3.4087e+00,\n",
       "          5.2591e+00,  5.1777e+00,  3.4814e+00,  1.3679e+00,  8.1738e+00,\n",
       "          2.4525e+00,  1.0261e+00, -1.6553e-01,  1.6946e+00,  1.4521e-01,\n",
       "          1.6762e+00,  4.1265e-03,  2.8590e+00,  2.1713e+00,  3.8845e+00,\n",
       "          9.8589e-01,  6.7571e+00,  2.8190e+00, -1.4173e-01,  1.1601e+00,\n",
       "          1.5839e+00,  4.6285e-01,  5.2077e+00,  4.3721e+00,  3.5753e+00,\n",
       "          1.3325e+00,  1.8123e+00,  1.7999e+00,  2.1096e+00,  1.7794e+00,\n",
       "          3.9813e+00,  4.4682e+00,  7.6398e-01,  2.6352e-01,  4.9766e+00,\n",
       "          2.3324e+00,  3.5732e+00,  1.3944e+00,  1.3990e+00,  1.1835e+00,\n",
       "          3.4451e+00,  2.2303e+00,  2.1103e+00,  1.3240e+00,  3.1431e+00,\n",
       "          6.5969e+00,  1.2751e+01,  8.6881e-01,  1.7982e+00,  3.4142e+00,\n",
       "          9.6931e+00,  1.4200e+00,  8.9574e+00,  5.4614e+00, -4.8185e-03,\n",
       "         -9.6324e-01,  2.2624e+00, -3.4234e-01,  8.0850e-01,  1.1402e-01,\n",
       "         -3.3357e-01,  2.2994e+00,  3.1390e+00,  1.2020e+00,  2.0513e+00,\n",
       "          8.0949e+00,  1.7100e+00,  1.5957e+00,  1.9009e+00,  2.1483e+00,\n",
       "          2.4537e+00,  3.1482e+00,  2.4470e+00, -1.1928e+00, -8.7503e-01,\n",
       "          7.1974e+00,  5.9918e-01,  2.7041e+00,  5.1352e+00,  1.8189e+00,\n",
       "          1.3887e+00,  2.3811e+00,  1.4596e+00,  1.7874e+00,  5.3509e+00,\n",
       "          4.7369e+00, -2.2328e+00,  1.9895e+00, -6.4411e-01,  1.6433e+00,\n",
       "          2.0578e+00,  1.0447e+01,  1.9834e+00,  2.4047e-01,  6.0685e+00,\n",
       "          2.4357e+00,  5.0865e+00,  9.5016e-01,  4.4344e+00,  5.1546e-01,\n",
       "          1.9999e+00,  2.9599e-01,  2.3816e+00,  1.2574e+00,  3.5008e-01,\n",
       "          3.5423e+00,  4.6877e-01,  5.8156e+00, -5.4048e-02, -2.6895e-01,\n",
       "          3.1356e+00,  1.5681e+00,  5.5011e-01,  1.2359e+00, -1.9735e-01,\n",
       "          3.4079e-01,  1.4495e+00,  1.0803e+01,  1.6715e+00,  1.3874e+00,\n",
       "          1.4548e+00, -1.0732e+00,  6.1231e-01,  5.7080e-02,  6.1017e-01,\n",
       "          3.4741e+00,  5.9747e+00,  2.7489e+00,  4.0058e-01,  8.9063e-01,\n",
       "          1.1260e+00,  1.8566e+00,  3.1607e+00,  2.7462e+00,  1.4243e+00,\n",
       "          1.6216e+00,  8.0088e+00,  2.2993e+00,  1.5136e+00,  1.3113e+00,\n",
       "          1.8477e+00,  1.6659e+00,  1.3972e+00,  4.1923e+00,  3.3145e+00,\n",
       "          5.0308e+00, -5.4860e-01,  1.4746e+00,  5.4576e+00,  2.4555e+00,\n",
       "          7.0378e+00, -2.2342e+00,  1.8802e+00,  2.8554e+00, -4.1374e-01,\n",
       "          1.2937e+00,  1.9048e+00,  2.5137e+00,  4.7178e-01,  9.6346e-01,\n",
       "          1.0314e+00,  4.9891e-01,  2.9938e-01,  8.3595e-01, -4.8503e-01,\n",
       "          3.3825e+00,  1.1654e+00,  2.4062e+00,  2.4643e-01,  2.7282e-01,\n",
       "          1.2085e+00,  3.5114e-01, -1.4447e-01,  3.0467e-01, -8.2387e-02,\n",
       "          5.4311e+00,  3.3766e+00,  2.4339e+00,  7.2189e-02,  3.6643e+00,\n",
       "          1.6018e-01,  2.7904e+00,  2.4824e-01,  7.8320e+00,  2.0488e+00,\n",
       "          3.7254e+00,  8.1951e+00,  5.2166e-01,  1.8777e+00,  1.4302e+00,\n",
       "          2.4088e+00,  2.2860e+00,  7.0445e-01,  2.0372e+00,  1.4686e+00,\n",
       "          2.9378e-01,  4.2124e+00,  2.1620e+00,  4.2861e+00,  2.8452e+00,\n",
       "          5.5121e-01,  4.4308e+00, -5.3647e-01, -5.3974e-01,  1.0069e-01,\n",
       "          2.2946e-01,  7.0993e+00,  7.2522e-01,  1.0623e+00,  2.2448e+00,\n",
       "         -1.0977e+00,  2.6975e+00,  4.8420e-01, -3.7558e-01,  1.3673e+00,\n",
       "         -3.9016e-01,  3.4436e-01,  6.7607e-01, -2.1698e+00,  3.3112e+00,\n",
       "         -4.7223e-01,  1.5182e+00, -4.0074e-01,  2.2247e+00,  1.2274e+00,\n",
       "          3.7444e+00,  8.6923e-01,  1.3067e+00,  3.4804e-01,  2.0140e-01,\n",
       "          1.2140e+00,  1.6870e+00,  3.1864e+00,  6.3255e-02,  5.2877e+00,\n",
       "          1.0072e+00, -1.4544e+00,  2.1303e+00,  2.5145e+00,  3.8221e-01,\n",
       "          7.4405e-01,  1.6814e-01,  1.6706e+00,  2.6756e+00,  3.0720e+00,\n",
       "         -2.3678e-01,  7.1499e-01,  2.5297e+00,  4.1388e+00,  8.9661e-01,\n",
       "          4.9800e+00,  5.1581e+00,  3.2843e+00,  4.2982e+00,  5.6683e+00,\n",
       "          3.3447e+00,  5.3973e+00,  2.6170e+00,  4.9077e+00,  2.2057e+00,\n",
       "         -2.3815e+00,  1.6280e+00,  1.3226e+00, -3.7113e-01,  1.7543e+00,\n",
       "         -5.2346e-01,  7.5114e+00,  1.6292e+00,  1.8685e+00, -1.2698e-01,\n",
       "          1.9972e+00,  1.4649e+00,  1.1401e+00,  8.3450e-01,  6.3220e-01,\n",
       "          3.8161e+00,  4.1096e+00,  2.6841e+00, -2.4357e-01,  1.1796e+00,\n",
       "         -2.6327e-01,  1.0861e+00,  5.7359e-01,  1.3336e+00,  1.1554e+00,\n",
       "          3.6330e-02, -1.2319e-01,  1.6008e+00,  3.1348e+00,  3.1109e+00,\n",
       "          4.0527e+00,  1.9590e+00, -3.1517e+00,  6.4728e+00,  3.9409e-01]),\n",
       " 'AI': tensor([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 100.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0., 100.,   0.,   0.,   0.,   0., 100.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0., 100.,   0.,   0.]),\n",
       " 'AD': tensor([ 2.3647e+02, -1.4576e+02,  3.9748e+03,  9.8957e+03, -7.5871e+02,\n",
       "         -9.7760e+02, -3.1503e+02, -1.6752e+04, -3.1103e+02,  1.1129e+04,\n",
       "          4.0353e+02,  2.3528e+02,  2.9986e+02,  1.8400e+03,  6.0554e+02,\n",
       "          1.8884e+02,  3.0441e+03,  3.6426e+02,  6.2211e+02, -1.2340e+02,\n",
       "         -2.7339e+02, -7.7735e+02,  3.5376e+02,  4.5576e+02,  1.7526e+02,\n",
       "          2.6453e+02,  2.3176e+02, -1.7233e+02, -1.3295e+03, -6.5103e+02,\n",
       "         -3.3419e+02, -1.5499e+02, -3.8324e+02, -1.7361e+02, -2.3411e+01,\n",
       "         -2.4246e+02, -2.2597e+02, -7.5754e+02, -4.8468e+02, -4.6225e+02,\n",
       "         -1.0972e+02,  4.9491e+02,  2.3892e+03,  5.5063e+02,  2.9472e+02,\n",
       "          7.5485e+02,  7.4435e+02, -8.1308e+01, -1.6179e+02, -5.0882e+03,\n",
       "          4.6493e+02, -1.2359e+03, -5.1790e+02, -4.9188e+02, -2.0890e+02,\n",
       "          6.2171e+02, -2.0030e+02,  6.8482e+02,  1.6371e+02, -2.4307e+02,\n",
       "         -2.9426e+02,  2.5056e+02,  2.4176e+02,  2.2095e+02,  3.4781e+02,\n",
       "          4.2226e+02,  2.7777e+02,  2.9276e+02,  2.6262e+02,  3.6285e+02,\n",
       "         -2.2837e+02,  3.0972e+02, -9.2518e+01,  5.9073e+02, -4.6088e+02,\n",
       "         -9.3684e+02,  3.0281e+02,  7.7833e+02,  1.4294e+03,  2.5082e+02,\n",
       "          3.7870e+02,  3.6875e+02,  6.5703e+02,  9.2978e+02,  2.7969e+02,\n",
       "          2.9793e+02, -1.1210e+03,  3.5641e+02,  1.9610e+03,  1.7668e+02,\n",
       "          3.7528e+03,  3.5445e+02,  1.5717e+02, -3.5002e+02, -1.0398e+03,\n",
       "          2.7311e+02,  1.6017e+04,  1.5176e+02, -8.0346e+02, -1.7687e+03,\n",
       "          1.6173e+02,  2.7773e+02,  1.2266e+03,  1.3251e+03,  5.7814e+02,\n",
       "          2.6048e+02,  2.1995e+02,  1.8343e+02,  3.0214e+02,  1.8247e+02,\n",
       "          2.1149e+02,  2.2920e+02, -8.6952e+02,  2.9208e+02, -5.5130e+02,\n",
       "          1.6741e+02, -9.1161e+01, -1.2568e+02, -1.3891e+02, -2.6887e+02,\n",
       "         -1.1890e+02,  3.1579e+02,  1.5681e+02, -9.6175e+02,  2.4737e+02,\n",
       "          2.5814e+02,  2.6936e+02,  1.4873e+02,  1.0389e+03,  5.4544e+02,\n",
       "         -2.8762e+03,  2.9171e+02,  3.1416e+02, -2.3491e+03,  5.3537e+02,\n",
       "          5.4180e+02,  5.8399e+02,  3.1704e+02,  3.5381e+02, -3.1067e+03,\n",
       "          4.1611e+02, -7.5104e+02,  2.4529e+02,  4.1535e+02,  2.0267e+02,\n",
       "          2.0602e+02,  1.8486e+02,  2.0956e+02, -3.9342e+02, -2.8037e+02,\n",
       "          1.3849e+02,  1.5150e+02,  1.5563e+02,  8.8420e+02,  1.9306e+02,\n",
       "          2.2318e+02, -1.3571e+02,  2.1705e+02,  1.3052e+03, -3.3474e+04,\n",
       "          2.0287e+02,  2.5560e+02,  2.4021e+02, -1.2043e+02,  9.1551e+01,\n",
       "          1.3067e+02,  6.7726e+02,  1.9724e+02,  6.7084e+02,  2.1548e+02,\n",
       "          2.9145e+02,  6.0104e+02,  2.6828e+02,  2.7982e+02,  4.8579e+02,\n",
       "          7.0340e+02, -1.5494e+02, -0.0000e+00, -5.8800e+01, -2.3855e+01,\n",
       "          1.8823e+02, -2.7252e+03,  2.7656e+03,  5.0432e+02,  4.8961e+02,\n",
       "          4.7353e+02,  1.5182e+03,  1.7132e+02,  2.6101e+02,  7.2721e+02,\n",
       "          1.0890e+03, -4.7534e+02,  1.5385e+03,  3.3549e+02,  2.1789e+02,\n",
       "          2.2822e+02,  3.1653e+02,  5.0054e+02,  1.4169e+03,  2.9992e+02,\n",
       "          2.3556e+02,  2.2972e+02,  2.4003e+02,  2.3041e+02, -1.7027e+03,\n",
       "          3.6239e+02, -2.2135e+02,  2.2491e+02,  2.1050e+02,  5.5163e+02,\n",
       "          2.9902e+02,  2.3253e+02,  6.0872e+02,  3.5163e+02,  8.3685e+02,\n",
       "          2.3414e+02,  1.9233e+02,  1.6402e+02,  1.9990e+02, -3.4047e+02,\n",
       "         -4.6096e+02, -6.0871e+02,  2.5806e+02,  2.9111e+02,  3.8799e+02,\n",
       "          1.7823e+02,  2.3462e+03,  2.7662e+02,  1.8164e+02, -8.2316e+02,\n",
       "         -1.3438e+03,  5.4790e+02,  2.6352e+02, -1.6551e+03,  4.8781e+02,\n",
       "          7.3918e+02,  1.9273e+02,  2.0440e+02,  8.8004e+02, -3.0310e+02,\n",
       "         -2.9361e+02,  1.6761e+02,  2.4876e+02,  1.8808e+02,  1.7520e+02,\n",
       "          4.2319e+02, -1.1153e+03,  3.5519e+02,  1.8834e+02, -1.1388e+03,\n",
       "          6.1682e+02, -1.1016e+03, -5.8671e+02,  3.6899e+02,  2.3125e+02,\n",
       "          2.6157e+02,  3.7930e+02,  3.2376e+02,  3.4810e+02, -4.6611e+01,\n",
       "          4.1728e+02, -5.9608e+01,  1.6014e+03,  1.8648e+02,  4.7489e+02,\n",
       "          3.6965e+02,  7.3371e+02,  1.8208e+02,  1.9967e+02, -5.3908e+01,\n",
       "         -1.4436e+03,  2.6516e+02,  2.7287e+02, -1.8890e+02, -8.1461e+01,\n",
       "         -5.4075e+02,  1.8472e+02, -1.0701e+02,  1.6653e+03, -1.8879e+02,\n",
       "          3.2875e+02,  2.1771e+02, -4.2904e+01, -3.4130e+02,  2.0348e+02,\n",
       "         -1.2459e+02,  3.2650e+02, -1.0582e+03,  2.2955e+02,  2.2054e+02,\n",
       "          3.9221e+02,  4.6596e+02,  5.5518e+03,  2.1218e+02,  3.0898e+02,\n",
       "          4.0550e+02,  1.6761e+03, -4.7255e+02,  3.0030e+02, -3.6121e+02,\n",
       "          2.4727e+02,  3.0243e+02, -5.3155e+02,  1.3489e+03, -1.0985e+03,\n",
       "          3.6887e+02,  1.8163e+03,  3.2616e+02, -4.1749e+02,  1.6267e+02,\n",
       "          1.3200e+02,  1.8065e+02,  1.8919e+02,  3.8274e+02,  4.4393e+02,\n",
       "         -7.2512e+02,  4.6335e+02,  1.3502e+02,  1.7843e+02,  1.4911e+02,\n",
       "          1.3899e+02,  2.3492e+02,  9.8550e+02,  6.1519e+02,  2.6848e+02,\n",
       "          2.8771e+02,  1.9296e+02,  9.3375e+03,  1.8470e+02,  1.4234e+03,\n",
       "          1.9239e+02, -2.1138e+02,  3.5241e+02, -2.6685e+03,  2.5347e+02,\n",
       "         -8.9565e+01, -2.5436e+02,  3.3258e+02,  2.1508e+02,  1.7305e+02,\n",
       "         -8.3682e+01,  2.5971e+02,  1.7791e+02,  4.4229e+02,  2.9391e+03,\n",
       "          2.2521e+02, -1.0730e+01,  1.8053e+02,  1.9259e+02,  2.8877e+02,\n",
       "         -4.1131e+02, -3.0967e+02, -2.6288e+02,  1.2960e+03, -6.4714e+01,\n",
       "          2.4185e+02,  2.0204e+02,  2.4057e+02,  3.0321e+02,  2.5406e+02,\n",
       "          2.3684e+02,  3.9885e+02,  2.9058e+02,  4.0857e+02,  2.4568e+02,\n",
       "         -0.0000e+00,  6.3499e+02,  4.5963e+02,  8.6252e+02,  1.7803e+02,\n",
       "         -0.0000e+00,  1.8144e+02,  1.1276e+02, -4.4679e+02, -3.2912e+02,\n",
       "          4.6990e+02, -4.1197e+02, -3.9345e+02,  6.1440e+02,  1.1693e+03,\n",
       "          2.8414e+02,  2.7634e+02,  1.2147e+03,  2.0772e+02, -1.0801e+02,\n",
       "         -7.1828e+01, -9.4924e+02,  2.7410e+03,  1.7904e+02, -2.5742e+01,\n",
       "         -1.1670e+03, -1.1454e+02,  5.6295e+02,  8.9434e+02,  1.5666e+02,\n",
       "          1.4600e+02,  4.5749e+02, -0.0000e+00,  3.1525e+02, -4.1032e+02]),\n",
       " 'AG': tensor([-0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "          0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "          0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  6.4573,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "         -0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "         -0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "         -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 15.8020,  0.0000,  0.0000,\n",
       "          0.0000, -0.0000, 21.1453, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "          0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 26.0342, -0.0000,  0.0000]),\n",
       " 'FidIn': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 1.]),\n",
       " 'SPS': tensor([0.5618, 0.8149, 0.7522, 0.8885, 0.5663, 0.9041, 0.5668, 0.5407, 0.5867,\n",
       "         0.8716, 0.5527, 0.5335, 0.6284, 0.5442, 0.5357, 0.5365, 0.5388, 0.5321,\n",
       "         0.5655, 0.6141, 0.6652, 0.5743, 0.5521, 0.5704, 0.5718, 0.5119, 0.5788,\n",
       "         0.5517, 0.5302, 0.5416, 0.5409, 0.5709, 0.5186, 0.5636, 0.5303, 0.5569,\n",
       "         0.5317, 0.5300, 0.5241, 0.5703, 0.5901, 0.5315, 0.5659, 0.5399, 0.6430,\n",
       "         0.5638, 0.5890, 0.5444, 0.8564, 0.6120, 0.7236, 0.5589, 0.5298, 0.5243,\n",
       "         0.5041, 0.5158, 0.5193, 0.5580, 0.5393, 0.5091, 0.5123, 0.8005, 0.7735,\n",
       "         0.7247, 0.8269, 0.5558, 0.5382, 0.5517, 0.5307, 0.5293, 0.6152, 0.5602,\n",
       "         0.5269, 0.4990, 0.5161, 0.5153, 0.5685, 0.5372, 0.6474, 0.5673, 0.5287,\n",
       "         0.5570, 0.5512, 0.5127, 0.5529, 0.5356, 0.5373, 0.8201, 0.5252, 0.6471,\n",
       "         0.8553, 0.5584, 0.5278, 0.5070, 0.4962, 0.5157, 0.5349, 0.5510, 0.5242,\n",
       "         0.6231, 0.5517, 0.5123, 0.5434, 0.5251, 0.6508, 0.5240, 0.6787, 0.6554,\n",
       "         0.7334, 0.6251, 0.6943, 0.6399, 0.5666, 0.6064, 0.5886, 0.5726, 0.5405,\n",
       "         0.5082, 0.5173, 0.5033, 0.5027, 0.5532, 0.5680, 0.5243, 0.5923, 0.5693,\n",
       "         0.5529, 0.5562, 0.5480, 0.5473, 0.5474, 0.6006, 0.5515, 0.5385, 0.5435,\n",
       "         0.4936, 0.6326, 0.5935, 0.5570, 0.5513, 0.5119, 0.5202, 0.6124, 0.6202,\n",
       "         0.5885, 0.6434, 0.6669, 0.6126, 0.5524, 0.5257, 0.5441, 0.5319, 0.5487,\n",
       "         0.7189, 0.5322, 0.5145, 0.6005, 0.5152, 0.5634, 0.5162, 0.6209, 0.5513,\n",
       "         0.5143, 0.5182, 0.5251, 0.5218, 0.8113, 0.6166, 0.5214, 0.5391, 0.5066,\n",
       "         0.5348, 0.6136, 0.6749, 0.5149, 0.5292, 0.5043, 0.5677, 0.5832, 0.5321,\n",
       "         0.5516, 0.5311, 0.5871, 0.5156, 0.5548, 0.5080, 0.8574, 0.5560, 0.5378,\n",
       "         0.5158, 0.5356, 0.5339, 0.6993, 0.5747, 0.5686, 0.5227, 0.4952, 0.5061,\n",
       "         0.5262, 0.6068, 0.5679, 0.5103, 0.5691, 0.5157, 0.5610, 0.5683, 0.4963,\n",
       "         0.5546, 0.5675, 0.5605, 0.5361, 0.5325, 0.5425, 0.5835, 0.6657, 0.5219,\n",
       "         0.5706, 0.6082, 0.5560, 0.5599, 0.5809, 0.5895, 0.6097, 0.5381, 0.5032,\n",
       "         0.5201, 0.5275, 0.5266, 0.5781, 0.6119, 0.6071, 0.5328, 0.6887, 0.5285,\n",
       "         0.5124, 0.5082, 0.5317, 0.5359, 0.7605, 0.8202, 0.8388, 0.5420, 0.5281,\n",
       "         0.5327, 0.5262, 0.6607, 0.6212, 0.5750, 0.5490, 0.8598, 0.8420, 0.7951,\n",
       "         0.6258, 0.5973, 0.8416, 0.8220, 0.5731, 0.5335, 0.8245, 0.6635, 0.5476,\n",
       "         0.5672, 0.5259, 0.5331, 0.5243, 0.5366, 0.5878, 0.5466, 0.5203, 0.4965,\n",
       "         0.5179, 0.8070, 0.5510, 0.7419, 0.5278, 0.5328, 0.7448, 0.5257, 0.5868,\n",
       "         0.8624, 0.8780, 0.6585, 0.5303, 0.5806, 0.5632, 0.7604, 0.5682, 0.5230,\n",
       "         0.7328, 0.7388, 0.5155, 0.5448, 0.5541, 0.7552, 0.6267, 0.6681, 0.6076,\n",
       "         0.5680, 0.5913, 0.7654, 0.5162, 0.6066, 0.5209, 0.5214, 0.7304, 0.5274,\n",
       "         0.5540, 0.4982, 0.5683, 0.5411, 0.5454, 0.7386, 0.5756, 0.5660, 0.5572,\n",
       "         0.5488, 0.6529, 0.5411, 0.5270, 0.5974, 0.5867, 0.5502, 0.7843, 0.5176,\n",
       "         0.4982, 0.5145, 0.5817, 0.5490, 0.5292, 0.5811, 0.5084, 0.5947, 0.5732,\n",
       "         0.5337, 0.5609, 0.5356, 0.5083, 0.5785, 0.5324, 0.5548, 0.6464, 0.5068,\n",
       "         0.6840, 0.5594, 0.5481, 0.5487, 0.5856, 0.5813, 0.6600, 0.8367, 0.5490,\n",
       "         0.5619, 0.5512, 0.5564, 0.8612, 0.6987, 0.6117, 0.5155, 0.5316, 0.5019,\n",
       "         0.5101, 0.5082, 0.5039, 0.5123, 0.5754, 0.5132, 0.5342, 0.5650, 0.8270,\n",
       "         0.6193, 0.5965, 0.7093, 0.5231, 0.8728, 0.7705, 0.5411, 0.7276, 0.8443,\n",
       "         0.5741, 0.8830, 0.8880, 0.8769, 0.5222, 0.5354, 0.8427, 0.5913, 0.5866,\n",
       "         0.5287, 0.5207, 0.5367, 0.5241, 0.5145, 0.5492, 0.5401, 0.5190, 0.5138,\n",
       "         0.5208, 0.5950, 0.5206, 0.6809], dtype=torch.float64),\n",
       " 'COMP': tensor([9.7917, 8.9728, 9.2606, 8.4146, 9.8081, 8.1352, 9.8142, 9.8550, 9.7679,\n",
       "         8.5153, 9.8280, 9.8702, 9.6244, 9.8578, 9.8651, 9.8660, 9.8709, 9.8842,\n",
       "         9.7932, 9.6347, 9.4527, 9.7699, 9.8327, 9.7915, 9.7934, 9.9242, 9.7535,\n",
       "         9.8375, 9.8799, 9.8489, 9.8600, 9.7799, 9.9084, 9.8108, 9.8755, 9.8130,\n",
       "         9.8743, 9.8847, 9.8919, 9.7878, 9.7349, 9.8739, 9.7867, 9.8644, 9.6050,\n",
       "         9.8223, 9.7370, 9.8453, 8.6932, 9.6841, 9.3535, 9.8219, 9.8776, 9.8980,\n",
       "         9.9361, 9.9148, 9.9087, 9.8224, 9.8682, 9.9246, 9.9234, 9.0320, 9.1675,\n",
       "         9.3654, 8.8610, 9.8177, 9.8678, 9.8242, 9.8782, 9.8844, 9.6576, 9.8103,\n",
       "         9.8850, 9.9497, 9.9144, 9.9160, 9.7960, 9.8651, 9.6131, 9.7976, 9.8883,\n",
       "         9.8199, 9.8300, 9.9213, 9.8282, 9.8667, 9.8657, 8.9197, 9.8987, 9.5658,\n",
       "         8.6834, 9.8227, 9.8907, 9.9242, 9.9517, 9.9159, 9.8723, 9.8265, 9.8969,\n",
       "         9.6459, 9.8278, 9.9195, 9.8462, 9.8836, 9.6020, 9.8937, 9.4851, 9.5409,\n",
       "         9.3035, 9.6555, 9.4442, 9.6097, 9.7966, 9.7156, 9.7264, 9.7810, 9.8508,\n",
       "         9.9288, 9.9050, 9.9409, 9.9399, 9.8323, 9.7878, 9.8977, 9.6982, 9.7879,\n",
       "         9.8241, 9.8195, 9.8513, 9.8484, 9.8439, 9.7160, 9.8272, 9.8642, 9.8453,\n",
       "         9.9560, 9.6394, 9.7395, 9.8253, 9.8375, 9.9178, 9.9078, 9.6867, 9.6591,\n",
       "         9.7386, 9.6096, 9.5448, 9.7021, 9.8192, 9.8918, 9.8541, 9.8805, 9.8373,\n",
       "         9.3453, 9.8785, 9.9191, 9.7096, 9.9183, 9.7969, 9.9119, 9.6357, 9.8360,\n",
       "         9.9121, 9.9086, 9.8944, 9.8953, 8.9213, 9.6567, 9.9038, 9.8612, 9.9285,\n",
       "         9.8686, 9.6687, 9.5284, 9.9180, 9.8847, 9.9352, 9.7925, 9.7508, 9.8678,\n",
       "         9.8357, 9.8795, 9.7426, 9.9184, 9.8227, 9.9299, 8.4814, 9.8241, 9.8624,\n",
       "         9.9170, 9.8572, 9.8697, 9.3250, 9.7842, 9.7954, 9.8978, 9.9577, 9.9378,\n",
       "         9.8933, 9.6867, 9.8011, 9.9259, 9.7935, 9.9102, 9.8143, 9.7992, 9.9530,\n",
       "         9.8299, 9.7928, 9.8183, 9.8733, 9.8758, 9.8614, 9.7615, 9.5160, 9.9034,\n",
       "         9.7899, 9.6442, 9.8081, 9.8210, 9.7554, 9.7555, 9.7136, 9.8659, 9.9390,\n",
       "         9.9036, 9.8840, 9.8796, 9.7547, 9.6836, 9.6934, 9.8742, 9.4242, 9.8812,\n",
       "         9.9204, 9.9303, 9.8802, 9.8618, 9.2292, 8.8769, 8.7755, 9.8505, 9.8791,\n",
       "         9.8763, 9.8891, 9.5443, 9.6501, 9.7738, 9.8398, 8.6278, 8.7685, 9.0778,\n",
       "         9.6345, 9.7233, 8.7398, 8.9122, 9.7836, 9.8777, 8.8531, 9.5465, 9.8430,\n",
       "         9.7712, 9.8818, 9.8754, 9.8903, 9.8555, 9.7631, 9.8520, 9.9011, 9.9522,\n",
       "         9.9119, 9.0061, 9.8226, 9.2964, 9.8850, 9.8781, 9.2814, 9.8916, 9.7452,\n",
       "         8.5471, 8.5150, 9.5651, 9.8772, 9.7638, 9.7973, 9.1954, 9.7965, 9.8953,\n",
       "         9.3427, 9.3172, 9.9131, 9.8517, 9.8335, 9.2537, 9.6195, 9.5358, 9.6961,\n",
       "         9.7874, 9.7194, 9.1768, 9.9099, 9.7024, 9.9044, 9.9059, 9.3429, 9.8818,\n",
       "         9.8286, 9.9510, 9.7814, 9.8512, 9.8349, 9.2690, 9.7661, 9.8002, 9.8170,\n",
       "         9.8413, 9.5982, 9.8617, 9.8842, 9.7265, 9.7302, 9.8293, 9.0471, 9.9103,\n",
       "         9.9512, 9.9184, 9.7563, 9.8237, 9.8830, 9.7593, 9.9302, 9.7287, 9.7725,\n",
       "         9.8707, 9.7972, 9.8603, 9.9308, 9.7759, 9.8764, 9.8285, 9.5721, 9.9322,\n",
       "         9.4516, 9.8177, 9.8374, 9.8356, 9.7640, 9.7635, 9.5590, 8.7271, 9.8377,\n",
       "         9.8138, 9.8306, 9.8257, 8.6428, 9.3828, 9.6739, 9.9141, 9.8806, 9.9420,\n",
       "         9.9265, 9.9306, 9.9351, 9.9183, 9.7834, 9.9192, 9.8647, 9.7861, 8.8282,\n",
       "         9.6630, 9.7098, 9.3777, 9.8963, 8.5004, 9.1377, 9.8530, 9.3518, 8.7400,\n",
       "         9.7850, 8.4763, 8.4078, 8.5212, 9.8956, 9.8714, 8.7406, 9.7294, 9.7539,\n",
       "         9.8836, 9.9064, 9.8689, 9.8995, 9.9144, 9.8401, 9.8618, 9.9069, 9.9176,\n",
       "         9.9014, 9.7461, 9.9033, 9.5095], dtype=torch.float64)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FF: 2.3136532306671143\n",
      "AI: 1.0\n",
      "AD: 166.3847198486328\n",
      "AG: 0.17359690368175507\n",
      "FidIn: 0.07750000059604645\n",
      "SPS: 0.5885762199361089\n",
      "COMP: 9.701299477654178\n"
     ]
    }
   ],
   "source": [
    "for m in results:\n",
    "    print(f\"{m}: {results[m].mean().item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
